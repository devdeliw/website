+++ 
title = "Understanding Memory" 
description = "Understanding how memory is stored and moved around" 
tags = ["BLAS"]
date = "2025-10-25" 
categories = ["Software"] 
menu = "main"
+++

{{< katex />}}

Before diving in to how BLAS is written to be fast, it's essential to understand
memory. Specifically, how data *is stored* into memory and how it *is fed* to
the processor, which does the calculations. All BLAS does is optimize these two
operations for a specific computer architecture. For CORAL, it's for AArch64.  

Future posts on BLAS will refer back to concepts explained here. 

> The content in this post is ***heavily*** taken from [*What Every Programmer
> Should Know About
> Memory*](https://people.freebsd.org/~lstewart/articles/cpumemory.pdf) by Ulrich Drepper. 
> It's phenomenal. Any values specified here, unless linked, were taken from this paper. 

--- 

## Memory 

*Memory* is a physical structure that stores digital information as stable
electrical states. A single *bit* of memory represents either a logical 0 or 1
by maintaining distinct, measurable voltages inside microscopic circuits. These
circuits exist in layers of *the memory hierarchy*, a set of memory storage levels
that trade off speed, capacity, and energy cost. 


{{% hint info %}}
For a fast BLAS, we want all our memory in use to exist in the *fastest*
memory storage level. 
{{% /hint %}}

{{% hint %}}
***Definition*** <br> 
A **clock cycle** is one complete oscillation of a processor's clock signal. It's
the periodic rise and fall of voltage that synchronizes every operation in the
CPU; the smallest **unit of computational time**. 
{{% /hint %}}


At the lowest level are *registers* inside the CPU itself. Accessing data from
registers takes $\leq 1$ cycle. Above registers are *caches*,
which exist in three sub-levels. Accessing cached data takes between $\sim$3-60 cycles
depending on which sub-level you have to travel to. Beyond caches lies the main
memory. Accessing data from main memory takes $\sim$200-400 cycles. Together these
levels form a pipeline that moves data from storage to the processor. 

<br>

<p align="center">
  <img src="/CPU.svg">
</p>

<br>


Naturally, the lower level storages are faster to read and write data to.
However, they are *much smaller* in size, trading capacity for speed. This will
be critical when discussing packing strategies for BLAS.

## Static and Dynamic RAM

All working memory in a computer is built on one of two forms of Random Access Memory (RAM): 
**Static** RAM (SRAM)  and **Dynamic** RAM (DRAM). Let's discuss why there
exists two forms at all, understand how they work, and the speed of reading from and writing to each.

### SRAM 

<div style="display: flex; justify-content: center;">
  <div
    style="
      mask: url('https://upload.wikimedia.org/wikipedia/commons/3/31/SRAM_Cell_%286_Transistors%29.svg') no-repeat center / contain;
      -webkit-mask: url('https://upload.wikimedia.org/wikipedia/commons/3/31/SRAM_Cell_%286_Transistors%29.svg') no-repeat center / contain;
      background-color: #898989;
      width: 70%;
      aspect-ratio: 1 / 1;
    "
  ></div>
</div>

This is one SRAM cell that can store a 0 or 1. The core of the cell is formed by
four transistors $M_1$ to $M_4$ that form two *cross-coupled* inverters/NOT
gates. This means each inverter output feeds the input of the other, shown
below. 


<p align="center">
  <img src="/cross-coupled.svg">
</p>


This loop, where the output of one inverter drives the input of the other,
creates *bistability*. The mutual inversion forms a feedback loop that can hold
one of two stable states, in the form of low or high voltages: 

$$ 
\begin{align*} 
Q = 1,\quad &\bar{Q} = 0 \\\\
Q = 0,\quad &\bar{Q} = 1 
\end{align*}
$$

This is the foundation of SRAM. These states can be held indefinitely as long as
power $V_{dd}$ is available to the cell -- SRAM is **static**. 

### DRAM 

<p align="center">
  <img src="/DRAM.svg">
</p>

DRAM, in its structure, is much simpler than SRAM. All it consists of is one
transistor $M$ and one capacitor $C$. A DRAM cell keeps its state in $C$. 
$M$ is used to guard access to the state. 

A stored 1 means the capacitor is charged; a 0 means discharged. However, a
modern DRAM capacitor is ***tiny*** -- on the order of 20-40 femtofarads. To store
a 1, a charge of $\sim 36 \times 10^{-15} C$ is placed on the capacitor. That's
36 femtocoulombs, or about 225,000 electrons.

Capacitors discharge or "leak". Every $\sim 64$ms they have to be refreshed/recharged. This 
doesn't stall the whole memory, but it does take up some cycles. To read data on the capacitor also requires discharging
it, *which takes more cycles*. But now the charge on the capacitor is
depleted, so every read also is followed by an operation to recharge the
capacitor, *which takes even more cycles*. 

A DRAM cell is much smaller than SRAM though. Packing many DRAM cells close together is
much simpler, and *less expensive*.  For this reason, caches use SRAM cells, where speed is critical. Main memory uses DRAM cells, where capacity is critical. A typical L1 cache may contain *tens of thousands* of SRAM cells, whereas main memory contains *trillions* of DRAM cells.

Let's walk through exactly how memory is read or written with SRAM versus DRAM. 

## Accessing Memory 

Both SRAM and DRAM cells are arranged in a 2D array. To access a row, the *wordline* $WL$ is
raised. It's a conductive path shared by all cells in a row. 

In SRAM, this opens two
access transistors -- $M_5$ and $M_6$ that allow the SRAM states to be read or
written to via the *bitline* $BL$. 

In DRAM, the raised wordline instead
activates the *single access transistor* $M$ that connects the capacitor $C$ to its
bitline. 

Reading or writing a bit in either SRAM or DRAM roughly follows these steps: 

{{% steps %}} 
1. **Select a Row (WL)** <br> 
    The memory controller raises a wordline. In SRAM this opens two access
    transistors. In DRAM this opens a single access transistor. 

2. **Connect to the Bitlines (BL)** <br> 
    Each column of cells shares a bitline. When connected, the cell either
    slightly raises or slightly lowers the voltage on that bitline depending on
    whether it stores 0 or 1. 

    In SRAM, this is practically instantaneous. In DRAM, this takes time
    (discharging and charging capacitors). 

3. **Sense Voltage Differences** <br> 
    The voltage change is incredibly small, only a few millivolts. Nearby
    **sense amplifiers** detect which direction (increase or decrease) the voltage
    change occurred. Then it amplifies the difference into a full digital 0V or 1V
    signal. 

4. **Deliver to the CPU** <br> 
    The sensed bits are combined into a word (for example, 64 bits), and
    transferred along metal interconnects towards the CPU's registers. Inside the
    processor, these signals are now conventional digital values, ready for
    arithmetic. 

{{% /steps %}}





